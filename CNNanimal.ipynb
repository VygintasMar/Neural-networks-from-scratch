{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6EcbIAJHO6Uf78f4z5rcw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VygintasMar/Neural-networks-from-scratch/blob/main/CNNanimal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "abge8TVFVRR8",
        "outputId": "b4d07577-4e08-4080-a586-d2184facaad5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:matplotlib.image:Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'bat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'cat', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'bee', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog', 'dog']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['bat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['cat']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['bee']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']\n",
            " ['dog']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/preprocessing/_encoders.py:868: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [1. 0. 0. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 0. 1. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 1. 0. 0.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]\n",
            " [0. 0. 0. 1.]]\n",
            "(192, 4)\n",
            "t after reshape [[0.]\n",
            " [1.]\n",
            " [0.]\n",
            " [0.]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.preprocessing.image import img_to_array\n",
        "\n",
        "# Initialize the OneHotEncoder\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = '/content/sample_data/animals'\n",
        "\n",
        "# Lists to store loaded images and labels\n",
        "X = []\n",
        "y = []\n",
        "\n",
        "# Image dimensions (change these to whatever dimensions you want)\n",
        "width, height = 64, 64  # Example dimensions\n",
        "\n",
        "# Load images and labels\n",
        "for folder in os.listdir(dataset_path):\n",
        "    if os.path.isdir(os.path.join(dataset_path, folder)):\n",
        "        for image_filename in os.listdir(os.path.join(dataset_path, folder)):\n",
        "            image_path = os.path.join(dataset_path, folder, image_filename)\n",
        "            image = Image.open(image_path).resize((width, height))\n",
        "            image = img_to_array(image)  # Convert image to numpy array\n",
        "            X.append(image)\n",
        "            y.append(folder)  # Using folder name as label\n",
        "print(y)\n",
        "# Convert lists to numpy arrays\n",
        "from matplotlib import pyplot as plt\n",
        "plt.imshow(X[61], interpolation='nearest')\n",
        "plt.show()\n",
        "X = np.array(X)/255\n",
        "y = np.array(y).reshape(-1, 1)  # Reshape y for encoder fitting\n",
        "print(y)\n",
        "\n",
        "# Encode labels\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "print(y_encoded)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2)\n",
        "print(np.shape(y_train))\n",
        "\n",
        "y_test = y_test.reshape(len(y_test), 4, 1)\n",
        "y_train = y_train.reshape(len(y_train), 4, 1)\n",
        "\n",
        "\n",
        "# Reshape X to add the grayscale channel dimension\n",
        "X_train = X_train.reshape(len(X_train), 3, width, height)\n",
        "X_test = X_test.reshape(len(X_test), 3, width, height)\n",
        "\n",
        "# Reshape y to match the specified format\n",
        "\n",
        "print('t after reshape', y_train[61])\n",
        "\n",
        "\n",
        "# Now X_train, X_test, y_train, and y_test are ready for CNN training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "data load above"
      ],
      "metadata": {
        "id": "1brMfZPThqpl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Layer:\n",
        "    def __init__(self):\n",
        "        self.input = None\n",
        "        self.output = None\n",
        "\n",
        "    def forward(self, input):\n",
        "        # TODO: return output\n",
        "        pass\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        # TODO: update parameters and return input gradient\n",
        "        pass"
      ],
      "metadata": {
        "id": "VTvjhhAZhlL5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy import signal"
      ],
      "metadata": {
        "id": "mt2qxEI8h0Co"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Convolutional(Layer):\n",
        "    def __init__(self, input_shape, kernel_size, depth):\n",
        "        input_depth, input_height, input_width = input_shape\n",
        "        self.depth = depth\n",
        "        self.input_shape = input_shape\n",
        "        self.input_depth = input_depth\n",
        "        self.output_shape = (depth, input_height - kernel_size + 1, input_width - kernel_size + 1)\n",
        "        self.kernels_shape = (depth, input_depth, kernel_size, kernel_size)\n",
        "        self.kernels = np.random.randn(*self.kernels_shape)\n",
        "        self.biases = np.random.randn(*self.output_shape)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        #print(np.shape(input), 'shape before cnn')\n",
        "        self.output = np.copy(self.biases)\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                self.output[i] += signal.correlate2d(self.input[j], self.kernels[i, j], \"valid\")\n",
        "\n",
        "        #print(np.shape(self.output), 'shape after cnn')\n",
        "        return self.output\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        kernels_gradient = np.zeros(self.kernels_shape)\n",
        "        input_gradient = np.zeros(self.input_shape)\n",
        "\n",
        "        for i in range(self.depth):\n",
        "            for j in range(self.input_depth):\n",
        "                kernels_gradient[i, j] = signal.correlate2d(self.input[j], output_gradient[i], \"valid\")\n",
        "                input_gradient[j] += signal.convolve2d(output_gradient[i], self.kernels[i, j], \"full\")\n",
        "\n",
        "        self.kernels -= learning_rate * kernels_gradient\n",
        "        self.biases -= learning_rate * output_gradient\n",
        "        return input_gradient\n"
      ],
      "metadata": {
        "id": "_ZNTOoBbhwJT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dense(Layer):\n",
        "    def __init__(self, input_size, output_size):\n",
        "        self.weights = np.random.randn(output_size, input_size)\n",
        "        self.bias = np.random.randn(output_size, 1)\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        #print(np.shape(input), 'shape before dense')\n",
        "        return np.dot(self.weights, self.input) + self.bias\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        weights_gradient = np.dot(output_gradient, self.input.T)\n",
        "        input_gradient = np.dot(self.weights.T, output_gradient)\n",
        "        self.weights -= learning_rate * weights_gradient\n",
        "        self.bias -= learning_rate * output_gradient\n",
        "        return input_gradient"
      ],
      "metadata": {
        "id": "ND5xD_5ZiMxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Activation(Layer):\n",
        "    def __init__(self, activation, activation_prime):\n",
        "        self.activation = activation\n",
        "        self.activation_prime = activation_prime\n",
        "\n",
        "    def forward(self, input):\n",
        "        self.input = input\n",
        "        return self.activation(self.input)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        #print(Layer)\n",
        "        return np.multiply(output_gradient, self.activation_prime(self.input))"
      ],
      "metadata": {
        "id": "Z8ky_CxTiWk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Tanh(Activation):\n",
        "    def __init__(self):\n",
        "        def tanh(x):\n",
        "            return np.tanh(x)\n",
        "\n",
        "        def tanh_prime(x):\n",
        "            return 1 - np.tanh(x) ** 2\n",
        "\n",
        "        super().__init__(tanh, tanh_prime)\n",
        "\n",
        "class Sigmoid(Activation):\n",
        "    def __init__(self):\n",
        "        def sigmoid(x):\n",
        "            return 1 / (1 + np.exp(-x))\n",
        "\n",
        "        def sigmoid_prime(x):\n",
        "            s = sigmoid(x)\n",
        "            return s * (1 - s)\n",
        "\n",
        "        super().__init__(sigmoid, sigmoid_prime)\n",
        "\n",
        "class Softmax(Layer):\n",
        "    def forward(self, input):\n",
        "        tmp = np.exp(input)\n",
        "        self.output = tmp / np.sum(tmp)\n",
        "        return self.output\n",
        "\n",
        "class Lrelu(Activation):\n",
        "  def __init__(self):\n",
        "    def leaky_relu(x):\n",
        "      if x>0 :\n",
        "        return x\n",
        "      else :\n",
        "        return 0.01*x\n",
        "\n",
        "    def relu_prime(x):\n",
        "        if x>0:\n",
        "          return 1\n",
        "        else:\n",
        "          return 0.01\n",
        "\n",
        "    super().__init__(Lrelu, relu_prime)"
      ],
      "metadata": {
        "id": "41Su4aa3ib3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mse(y_true, y_pred):\n",
        "    return np.mean(np.power(y_true - y_pred, 2))\n",
        "\n",
        "def mse_prime(y_true, y_pred):\n",
        "    return 2 * (y_pred - y_true) / np.size(y_true)\n",
        "\n",
        "def binary_cross_entropy(y_true, y_pred):\n",
        "    return np.mean(-y_true * np.log(y_pred) - (1 - y_true) * np.log(1 - y_pred))\n",
        "\n",
        "def binary_cross_entropy_prime(y_true, y_pred):\n",
        "    return ((1 - y_true) / (1 - y_pred) - y_true / y_pred) / np.size(y_true)"
      ],
      "metadata": {
        "id": "fK84MkEoifFY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Reshape(Layer):\n",
        "    def __init__(self, input_shape, output_shape):\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = output_shape\n",
        "\n",
        "    def forward(self, input):\n",
        "        #print(np.shape(input), 'shape before reshape')\n",
        "        #print(np.shape(np.reshape(input, self.output_shape)), 'shape after reshape')\n",
        "        return np.reshape(input, self.output_shape)\n",
        "\n",
        "    def backward(self, output_gradient, learning_rate):\n",
        "        #print(np.shape(input), 'shape after reshape')\n",
        "        return np.reshape(output_gradient, self.input_shape)"
      ],
      "metadata": {
        "id": "vAPIihfJioZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "model definition above"
      ],
      "metadata": {
        "id": "sw11VIAziyTK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(network, input):\n",
        "    output = input\n",
        "    for layer in network:\n",
        "        output = layer.forward(output)\n",
        "        #print(np.size(output))\n",
        "    return output\n",
        "\n",
        "def train(network, loss, loss_prime, x_train, y_train, epochs = 1000, learning_rate = 0.01, verbose = True):\n",
        "    for e in range(epochs):\n",
        "        error = 0\n",
        "        print(e, \"  epoch    \")\n",
        "        for x, y in zip(x_train, y_train):\n",
        "            # forward\n",
        "            output = predict(network, x)\n",
        "\n",
        "            # error\n",
        "            error += loss(y, output)\n",
        "            #print(error, \"  error  \")\n",
        "\n",
        "            # backward\n",
        "            grad = loss_prime(y, output)\n",
        "            for layer in reversed(network):\n",
        "                grad = layer.backward(grad, learning_rate)\n",
        "                #print(grad)\n",
        "\n",
        "        error /= len(x_train)\n",
        "        if verbose:\n",
        "            print(f\"{e + 1}/{epochs}, error={error}\")"
      ],
      "metadata": {
        "id": "WIz8r5BLi7p8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "training loop"
      ],
      "metadata": {
        "id": "DePp1rxLjB1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network = [\n",
        "    Convolutional((3, 64, 64), 3, 5),\n",
        "    Sigmoid(),\n",
        "    Convolutional((5, 62, 62), 3, 5),\n",
        "    Tanh(),\n",
        "    Reshape((5, 60, 60), (5 * 60 * 60, 1)),\n",
        "    Dense(5 * 60 * 60, 10),\n",
        "    Sigmoid(),\n",
        "    Dense(10, 4)\n",
        "]\n",
        "\n",
        "# train\n",
        "train(\n",
        "    network,\n",
        "    mse,\n",
        "    mse_prime,\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=50,\n",
        "    learning_rate=0.01\n",
        ")\n",
        "\n",
        "# test\n",
        "for x, y in zip(X_test, y_test):\n",
        "    output = predict(network, x)\n",
        "    print(f\"pred: {np.argmax(output)}, true: {np.argmax(y)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaaPTtwIjDeM",
        "outputId": "4613c399-1cae-4450-ddca-f73ac5d423d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0   epoch    \n",
            "1/50, error=0.8579007736060604\n",
            "1   epoch    \n",
            "2/50, error=0.20200727457631404\n",
            "2   epoch    \n",
            "3/50, error=0.19206598071019823\n",
            "3   epoch    \n",
            "4/50, error=0.19205644831191218\n",
            "4   epoch    \n",
            "5/50, error=0.19205644458965143\n",
            "5   epoch    \n",
            "6/50, error=0.19205644458810603\n",
            "6   epoch    \n",
            "7/50, error=0.1920564445880286\n",
            "7   epoch    \n",
            "8/50, error=0.19205644458795168\n",
            "8   epoch    \n",
            "9/50, error=0.19205644458787485\n",
            "9   epoch    \n",
            "10/50, error=0.19205644458779803\n",
            "10   epoch    \n",
            "11/50, error=0.19205644458772098\n",
            "11   epoch    \n",
            "12/50, error=0.19205644458764412\n",
            "12   epoch    \n",
            "13/50, error=0.1920564445875673\n",
            "13   epoch    \n",
            "14/50, error=0.19205644458749047\n",
            "14   epoch    \n",
            "15/50, error=0.19205644458741353\n",
            "15   epoch    \n",
            "16/50, error=0.19205644458733653\n",
            "16   epoch    \n",
            "17/50, error=0.1920564445872596\n",
            "17   epoch    \n",
            "18/50, error=0.1920564445871826\n",
            "18   epoch    \n",
            "19/50, error=0.19205644458710555\n",
            "19   epoch    \n",
            "20/50, error=0.19205644458702867\n",
            "20   epoch    \n",
            "21/50, error=0.1920564445869516\n",
            "21   epoch    \n",
            "22/50, error=0.19205644458687476\n",
            "22   epoch    \n",
            "23/50, error=0.19205644458679774\n",
            "23   epoch    \n",
            "24/50, error=0.1920564445867208\n",
            "24   epoch    \n",
            "25/50, error=0.19205644458664375\n",
            "25   epoch    \n",
            "26/50, error=0.19205644458656654\n",
            "26   epoch    \n",
            "27/50, error=0.1920564445864897\n",
            "27   epoch    \n",
            "28/50, error=0.1920564445864127\n",
            "28   epoch    \n",
            "29/50, error=0.19205644458633556\n",
            "29   epoch    \n",
            "30/50, error=0.19205644458625837\n",
            "30   epoch    \n",
            "31/50, error=0.19205644458618135\n",
            "31   epoch    \n",
            "32/50, error=0.1920564445861044\n",
            "32   epoch    \n",
            "33/50, error=0.19205644458602714\n",
            "33   epoch    \n",
            "34/50, error=0.19205644458595003\n",
            "34   epoch    \n",
            "35/50, error=0.19205644458587298\n",
            "35   epoch    \n",
            "36/50, error=0.19205644458579565\n",
            "36   epoch    \n",
            "37/50, error=0.19205644458571847\n",
            "37   epoch    \n",
            "38/50, error=0.19205644458564128\n",
            "38   epoch    \n",
            "39/50, error=0.19205644458556428\n",
            "39   epoch    \n",
            "40/50, error=0.1920564445854872\n",
            "40   epoch    \n",
            "41/50, error=0.19205644458541002\n",
            "41   epoch    \n",
            "42/50, error=0.19205644458533278\n",
            "42   epoch    \n",
            "43/50, error=0.19205644458525575\n",
            "43   epoch    \n",
            "44/50, error=0.19205644458517845\n",
            "44   epoch    \n",
            "45/50, error=0.19205644458510118\n",
            "45   epoch    \n",
            "46/50, error=0.19205644458502402\n",
            "46   epoch    \n",
            "47/50, error=0.19205644458494672\n",
            "47   epoch    \n",
            "48/50, error=0.1920564445848694\n",
            "48   epoch    \n",
            "49/50, error=0.19205644458479218\n",
            "49   epoch    \n",
            "50/50, error=0.1920564445847149\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 0\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 1\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 2\n",
            "pred: 1, true: 3\n",
            "pred: 1, true: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BuN_MsTgT0Tx"
      }
    }
  ]
}